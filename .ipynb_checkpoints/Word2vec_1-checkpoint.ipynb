{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.577 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document  1  well done.\n",
      "document  2  well done.\n",
      "document  3  well done.\n",
      "document  4  well done.\n",
      "document  5  well done.\n",
      "document  6  well done.\n",
      "document  7  well done.\n",
      "document  8  well done.\n",
      "document  9  well done.\n",
      "document  10  well done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# coding=utf-8\n",
    "# 采用Word2Vec词聚类方法抽取关键词1——获取文本词向量表示\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')  # 忽略警告\n",
    "import sys, codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "import gensim\n",
    "\n",
    "# 返回特征词向量\n",
    "def getWordVecs(wordList, model):\n",
    "    name = []\n",
    "    vecs = []\n",
    "    for word in wordList:\n",
    "        word = word.replace('\\n', '')\n",
    "        try:\n",
    "            if word in model:  # 模型中存在该词的向量表示\n",
    "                name.append(word)\n",
    "                vecs.append(model[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    a = pd.DataFrame(name, columns=['word'])\n",
    "    b = pd.DataFrame(np.array(vecs, dtype='float'))\n",
    "    return pd.concat([a, b], axis=1)\n",
    "\n",
    "# 数据预处理操作：分词，去停用词，词性筛选\n",
    "def dataPrepos(text, stopkey):\n",
    "    l = []\n",
    "    pos = ['n', 'nz', 'v', 'vd', 'vn', 'l', 'a', 'd']  # 定义选取的词性\n",
    "    seg = jieba.posseg.cut(text)  # 分词\n",
    "    for i in seg:\n",
    "        if i.word not in l and i.word not in stopkey and i.flag in pos:  # 去重 + 去停用词 + 词性筛选\n",
    "            # print i.word\n",
    "            l.append(i.word)\n",
    "    return l\n",
    "\n",
    "# 根据数据获取候选关键词词向量\n",
    "def buildAllWordsVecs(data, stopkey, model):\n",
    "    idList, titleList, abstractList = data['id'], data['title'], data['abstract']\n",
    "    for index in range(len(idList)):\n",
    "        id = idList[index]\n",
    "        title = titleList[index]\n",
    "        abstract = abstractList[index]\n",
    "        l_ti = dataPrepos(title, stopkey)  # 处理标题\n",
    "        l_ab = dataPrepos(abstract, stopkey)  # 处理摘要\n",
    "        # 获取候选关键词的词向量\n",
    "        words = np.append(l_ti, l_ab)  # 拼接数组元素\n",
    "        words = list(set(words))  # 数组元素去重,得到候选关键词列表\n",
    "        wordvecs = getWordVecs(words, model)  # 获取候选关键词的词向量表示\n",
    "        # 词向量写入csv文件，每个词400维\n",
    "        data_vecs = pd.DataFrame(wordvecs)\n",
    "        data_vecs.to_csv('result/vecs/wordvecs_' + str(id) + '.csv', index=False)\n",
    "        print( \"document \", id, \" well done.\")\n",
    "\n",
    "def main():\n",
    "    # 读取数据集\n",
    "    dataFile = 'data/sample_data.csv'\n",
    "    data = pd.read_csv(dataFile)\n",
    "    # 停用词表\n",
    "    stopkey = [w.strip() for w in codecs.open('data/stopWord.txt', 'r',encoding='utf-8').readlines()]\n",
    "    # 词向量模型\n",
    "    inp = 'wiki.zh.text.vector'\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(inp, binary=False)\n",
    "    buildAllWordsVecs(data, stopkey, model)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
